from requests_html import HTMLSession
from urllib.parse import urljoin, urlparse
import requests
import pyjsparser
import jsbeautifier

def get_session(url):
    session = HTMLSession()
    return session.get(urlparse(url, "http").geturl())
    # https://requests-html.kennethreitz.org/_static/doctools.js
    
    
def get_scripts(url, session):
    scripts = []
    for script in session.html.find("script"):
        current = []
        if "src" in script.attrs:
            current.append("linked")
            current.append(requests.get(urljoin(url, script.attrs["src"])).text.replace("”", "\""))
        else:
            current.append("inline")
            current.append(script.text.replace("”", "\""))
        scripts.append(current)
    return scripts

def parse(js_content):
    return pyjsparser.parse(jsbeautifier.beautify(js_content))

def get_file_from_web(url):
    pass

def get_recursively(search_dict, field):
    fields_found = []

    for key, value in search_dict.items():
        if key == field:
            print(key)
            fields_found.append(value)

        elif isinstance(value, dict):
            results = get_recursively(value, field)
            for result in results:
                fields_found.append(result)

        elif isinstance(value, list):
            for item in value:
                if isinstance(item, dict):
                    more_results = get_recursively(item, field)
                    for another_result in more_results:
                        fields_found.append(another_result)

    return fields_found